# NADB Benchmark Status
## User Guide
- é¦–å…ˆæŠŠæ•°æ®è½¬æ¢ä¸ºå›¾çš„å½¢å¼ .gpickleæˆ–è€….graphml
cd data_gen/graph_gen
python run.py

- æ¨¡æ‹Ÿå™ªå£°å›¾ï¼Œè®°å½•å™ªå£°ç‚¹çš„ä½ç½®ï¼š
cd data_gen
python graph_generator.py

- ç”Ÿæˆæ£€æµ‹æŸ¥è¯¢ï¼ˆå™ªå£°å›¾ä¸Šï¼šå™ªå£°ç‚¹å’Œå¹²å‡€ç‚¹ä¸Šçš„å¤æ‚æŸ¥è¯¢æ£€æµ‹ï¼›å¹²å‡€å›¾ä¸Šï¼šå¢åˆ æ”¹ç›¸å…³çš„æŸ¥è¯¢ç”Ÿæˆï¼‰ï¼š
  æŸ¥è¯¢åˆ†ä¸ºå‡ ç±»ï¼š
  complex1ï¼Œcomplex2(åˆ¤æ–­é¢˜), management
cd pipeline/query_gen
python qgen_test_noise

- æ¸…æ´—æŸ¥è¯¢ç»“æœ

- å¾—åˆ°nlpæè¿°
cd pipeline/handler
python translate.py
(è®°å¾—ä¿®æ”¹æ–‡ä»¶å)

## neo4jçš„ä½¿ç”¨
è¯¦è§pipeline/query_module/db_base.py

    ```python
    uri = "bolt://localhost:7693"
    user = "neo4j"
    password = "fei123456"
    
    # è¾“å…¥å’Œè¾“å‡ºæ–‡ä»¶è·¯å¾„
    input_json_file = "../query_gen/query/ldbc_snb_finbench/noise_query_results_ldbcfin_cleaned.json"
    output_json_file = "noise_execution_step1_ldbcfin_results.json"
    
    # åˆ›å»ºæ•°æ®åº“æ‰§è¡Œå™¨
    executor = DatabaseExecutor(uri, user, password)
    
    try:
        # è¿æ¥æ•°æ®åº“
        executor.connect()
        
        # è¯»å–æŸ¥è¯¢
        queries = executor.read_queries_from_json(input_json_file)
        
        # æ‰§è¡ŒæŸ¥è¯¢å¹¶æ¯”è¾ƒç»“æœï¼Œå¯ç”¨å¢é‡ä¿å­˜ï¼ˆä¸€è¾¹æ‰§è¡Œä¸€è¾¹è®°å½•ï¼‰
        results = executor.execute_queries_batch(
            queries, 
            compare_with_original=True,
            incremental_save=True,  # å¯ç”¨å¢é‡ä¿å­˜
            output_file_path=output_json_file
        )
    ```
ç›®å‰å·²æœ‰å‡ ä¸ªæ•°æ®åº“å®¹å™¨å¦‚ä¸‹ï¼š
é‡‘èæ–‡æ¡£æ•°æ®ï¼š
```bash
# é‡‘èæ–‡æ¡£æ•°æ®ï¼š
docker run \
  --name neo4j-520 \
  -p 7689:7687 \
  -e NEO4J_AUTH=neo4j/fei123456 \
  neo4j:5.20.0

# mcpæ•°æ®ï¼š
docker run \
  --name neo4j-mcp \
  -p 7690:7687 \
  -e NEO4J_AUTH=neo4j/fei123456 \
  neo4j:5.20.0

# ldbcbiæ•°æ®ï¼š
docker run \
  --name neo4j-ldbcbi \
  -p 7691:7687 \
  -e NEO4J_AUTH=neo4j/fei123456 \
  neo4j:5.20.0

# ldbcfinæ•°æ®ï¼š
docker run \
  --name neo4j-ldbcfin \
  -p 7692:7687 \
  -e NEO4J_AUTH=neo4j/fei123456 \
  neo4j:5.20.0

# ldbcfin-noise æ•°æ®ï¼š
docker run \
  --name neo4j-ldbcfin-noise \
  -p 7693:7687 \
  -e NEO4J_AUTH=neo4j/fei123456 \
  neo4j:5.20.0

# ldbcfin-manage æ•°æ®ï¼š
docker run \
  --name neo4j-ldbcfin-manage \
  -p 7694:7687 \
  -e NEO4J_AUTH=neo4j/fei123456 \
  neo4j:5.20.0
```
  
## Data Generation Module Status
- âœ… Random incompleteness generation is done.
- âœ… Random noise generation is done.
- âœ… Semantic perturbation is done. (But I only tested it on Primekg dataset)
- âœ… pipeline/data_analyser(containing the dataloader) is working
  - On how to use the dataloader, you can refer to the test code in file dataload_toolkit.py.
  - In the data_analyser module, there is a buffer directory which stores the ldbc_snb_bi_graph.gpickle, but it is gitignored due to the huge size. You can access it on the machine CPU8`/data/ylivm/ngdb_benchmark/pipeline/data_analyser/buffer` (but actually generating the gpickle file from scratch takes few minutes.)
- ğŸš§ Coming soon:
  - The next important step is to construct the query generation module.
  - topology_perturbation is not considered in current stage.

## Usage Guide
For detailed instructions on using the data_gen module, please see [data_gen/readme.md](data_gen/readme.md).

## Generated Datasets
The currently generated datasets are stored at:
GPU8 `/data/ylivm/ngdb_benchmark/data_gen/perturbed_dataset`, you can refer to `/data/ylivm/ngdb_benchmark/data_gen/perturb_record` for what have happened.

In the data_analyser module, there is a buffer directory which stores the ldbc_snb_bi_graph.gpickle, but it is gitignored due to the huge size. You can access it on the machine(but actually generating the gpickle file from scratch takes few minutes.)